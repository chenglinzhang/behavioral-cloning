{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Dropout, Flatten, Dense\n",
    "from keras.layers import Cropping2D, Conv2D\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset with python csv reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    lines = []\n",
    "    with open(data_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter extreme steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(lines):\n",
    "    filtered = []\n",
    "    for line in lines:\n",
    "        angle = float(line[3])\n",
    "        if (angle < -0.95 or angle > +0.95):\n",
    "            continue\n",
    "        filtered.append(line)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read image with OpenCV and convert to RGB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    image_path = './data/' + path.strip()\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)   \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment center, left, right of each data line with their flipped images and steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(line, correction = 0.20):\n",
    "    images = []\n",
    "    angles = []\n",
    "    \n",
    "    center_image = read_image(line[0])\n",
    "    left_image = read_image(line[1])\n",
    "    right_image = read_image(line[2])\n",
    "    \n",
    "    center_angle = float(line[3])\n",
    "    left_angle = center_angle + correction\n",
    "    right_angle = center_angle - correction\n",
    "    \n",
    "    images.append(center_image)\n",
    "    angles.append(center_angle)\n",
    "    images.append(cv2.flip(center_image, 1))\n",
    "    angles.append(-center_angle)\n",
    "    \n",
    "    images.append(left_image)\n",
    "    angles.append(left_angle)\n",
    "    images.append(cv2.flip(left_image, 1))\n",
    "    angles.append(-left_angle)\n",
    "    \n",
    "    images.append(right_image)\n",
    "    angles.append(right_angle)\n",
    "    images.append(cv2.flip(right_image, 1))\n",
    "    angles.append(-right_angle)\n",
    "    \n",
    "    return images, angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data batches with python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataset, batch_size = 32):\n",
    "    n = len(dataset)\n",
    "    while True: \n",
    "        shuffle(dataset)\n",
    "        for offset in range(0, n, batch_size):\n",
    "            batch = dataset[offset : offset + batch_size]\n",
    "\n",
    "        images = []\n",
    "        angles = []\n",
    "        for line in batch:            \n",
    "            augmented_images, augmented_angles = augment_data(line)\n",
    "            images.extend(augmented_images)\n",
    "            angles.extend(augmented_angles)\n",
    "\n",
    "        x_train = np.array(images)\n",
    "        y_train = np.array(angles)\n",
    "\n",
    "        yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Nvidia CNN model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape = (160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping = ((60, 20), (0, 0))))\n",
    "    \n",
    "    model.add(Conv2D(24, 5, strides = (2, 2), activation = 'relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Conv2D(36, 5, strides = (2, 2), activation = 'relu'))\n",
    "    model.add(Conv2D(48, 5, strides = (2, 2), activation = 'relu'))\n",
    "    model.add(Conv2D(64, 3, activation = 'relu'))\n",
    "    model.add(Conv2D(64, 3, activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main to train, validate and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = nvidia_model()\n",
    "    model.summary()\n",
    "    \n",
    "    lines = load_data('./data/driving_log.csv')\n",
    "    filtered_lines = filter_data(lines)\n",
    "    \n",
    "    train_dataset, valid_dataset = train_test_split(filtered_lines, test_size = 0.2)\n",
    "    train_generator = generate_data(train_dataset, batch_size = 32)\n",
    "    valid_generator = generate_data(valid_dataset, batch_size = 32)\n",
    "\n",
    "    model.fit_generator(train_generator,\n",
    "        steps_per_epoch = len(train_dataset),\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = len(valid_dataset),\n",
    "        epochs = 21\n",
    "        )\n",
    "    \n",
    "    model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)    (None, 80, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 38, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 17, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6336)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               633700    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 770,619\n",
      "Trainable params: 770,619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "6427/6427 [==============================] - 608s 95ms/step - loss: 0.0012 - val_loss: 0.0444\n",
      "Epoch 2/21\n",
      "6427/6427 [==============================] - 584s 91ms/step - loss: 4.1983e-05 - val_loss: 0.0377\n",
      "Epoch 3/21\n",
      "6427/6427 [==============================] - 602s 94ms/step - loss: 1.6480e-05 - val_loss: 0.0349\n",
      "Epoch 4/21\n",
      "6427/6427 [==============================] - 603s 94ms/step - loss: 8.5680e-06 - val_loss: 0.0350\n",
      "Epoch 5/21\n",
      "6427/6427 [==============================] - 596s 93ms/step - loss: 5.5519e-06 - val_loss: 0.0361\n",
      "Epoch 6/21\n",
      "6427/6427 [==============================] - 592s 92ms/step - loss: 1.9634e-05 - val_loss: 0.0393\n",
      "Epoch 7/21\n",
      "6427/6427 [==============================] - 610s 95ms/step - loss: 4.4542e-06 - val_loss: 0.0418\n",
      "Epoch 8/21\n",
      "6427/6427 [==============================] - 641s 100ms/step - loss: 8.0190e-06 - val_loss: 0.0447\n",
      "Epoch 9/21\n",
      "6427/6427 [==============================] - 616s 96ms/step - loss: 3.9896e-06 - val_loss: 0.0420\n",
      "Epoch 10/21\n",
      "6427/6427 [==============================] - 598s 93ms/step - loss: 6.2314e-06 - val_loss: 0.0429\n",
      "Epoch 11/21\n",
      "6427/6427 [==============================] - 598s 93ms/step - loss: 2.9851e-06 - val_loss: 0.0433\n",
      "Epoch 12/21\n",
      "6427/6427 [==============================] - 602s 94ms/step - loss: 2.0091e-06 - val_loss: 0.0433\n",
      "Epoch 13/21\n",
      "6427/6427 [==============================] - 602s 94ms/step - loss: 1.6596e-06 - val_loss: 0.0427\n",
      "Epoch 14/21\n",
      "6427/6427 [==============================] - 604s 94ms/step - loss: 9.2027e-06 - val_loss: 0.0440\n",
      "Epoch 15/21\n",
      "6427/6427 [==============================] - 607s 94ms/step - loss: 1.8620e-06 - val_loss: 0.0418\n",
      "Epoch 16/21\n",
      "6427/6427 [==============================] - 606s 94ms/step - loss: 3.5712e-06 - val_loss: 0.0448\n",
      "Epoch 17/21\n",
      "6427/6427 [==============================] - 611s 95ms/step - loss: 1.1510e-06 - val_loss: 0.0411\n",
      "Epoch 18/21\n",
      "6427/6427 [==============================] - 611s 95ms/step - loss: 2.6715e-06 - val_loss: 0.0414\n",
      "Epoch 19/21\n",
      "6427/6427 [==============================] - 613s 95ms/step - loss: 6.6540e-06 - val_loss: 0.0462\n",
      "Epoch 20/21\n",
      "6427/6427 [==============================] - 613s 95ms/step - loss: 1.2629e-06 - val_loss: 0.0425\n",
      "Epoch 21/21\n",
      "6427/6427 [==============================] - 613s 95ms/step - loss: 2.2225e-06 - val_loss: 0.0481\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
